# ğŸ“š Knowledge Scout

**Knowledge Scout** is a Python project that processes data from CSV or TXT files, stores them in a vector database, and answers your questions using **RAG (Retrieval-Augmented Generation)** architecture. It offers a flexible structure with chat history management, custom prompt design, and support for multiple LLMs.

## âš™ï¸ Features

* **Multi-format data loading** â€” Support for `.csv` and `.txt` files
* **LangChain integration** for document processing and chunking
* **HuggingFace Embeddings** for vector generation
* **ChromaDB** for persistent vector storage
* **MultiQueryRetriever** for improved search results
* **Gpt4FreeLLM** or **CustomLLM** options
* **Chat history clearing** functionality
* **Fully interactive terminal-based usage**

## ğŸ“‚ Project Structure

```bash
knowledge-scout/
â”‚
â”œâ”€â”€ data_handler.py     # DataLoader class â€” Data loading and Document creation
â”œâ”€â”€ rag_system.py       # RagSystem class â€” RAG pipeline creation and querying
â”œâ”€â”€ llm_model.py        # Gpt4FreeLLM and CustomLLM classes
â”œâ”€â”€ main.py             # Entry point â€” CLI-based usage
â”œâ”€â”€ requirements.txt    # Dependencies
â””â”€â”€ doc/
    â””â”€â”€ Top_Anime_data.csv
```

## ğŸ›  Installation

1. **Clone the project**

```bash
git clone https://github.com/zeynepcagil/knowledge-scout.git
cd knowledge-scout
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **(Optional) Set up OpenAI API key**
   If you want to use `CustomLLM`:

```python
openai_api_token = "YOUR_API_KEY"  # inside main.py
```

## ğŸš€ Usage

1. **Run the main file**

```bash
python main.py
```

2. **Using with default file**
   The project uses the `doc/Top_Anime_data.csv` file by default.

3. **To use your own data**
   * Change the line in `main.py`:

```python
csv_path = "doc/Top_Anime_data.csv"
```

   to your own `.csv` or `.txt` file path.

4. **Commands**
   * `q` â†’ Exit the program
   * `temizle` â†’ Clear chat history
   * All other inputs are sent as questions to the system.

## ğŸ§© Components

### **1. DataLoader**
* Reads `.csv` and `.txt` files
* Converts rows or entire text into `Document` objects
* In CSV loading, each row is saved with metadata (headers, row index)

### **2. RagSystem**
* Splits documents into chunks (`RecursiveCharacterTextSplitter`)
* Vectorizes using HuggingFace Embeddings
* Stores in ChromaDB
* Generates richer queries with MultiQueryRetriever
* Includes custom Turkish-English translation-supported search prompt
* Manages chat history with `ConversationBufferWindowMemory`

### **3. LLM Models**
* **Gpt4FreeLLM** â€” Free model access through g4f library
* **CustomLLM** â€” OpenAI API compatible request sending

### **4. main.py**
* Manages the flow: Data loading â†’ RAG pipeline initialization â†’ CLI question asking

## ğŸ“Œ Example Usage

```bash
Enter your question: What is the release year of Naruto?
Answer: 2002
```

```bash
Enter your question: temizle
Chat GeÃ§miÅŸ temizlendi.
```

## ğŸ¤ Contributing

To contribute:
1. Create a fork
2. Create a new branch
3. Commit your changes
4. Send a pull request